{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code reads the 4D training/testing data arrays, calculates the mean and std values of each of the bands, gets the sample prediction from the trained CNN and saves it all into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import xml.etree.ElementTree as ET\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that takes the 4D input array normalizes the data and returns the ice/water prediction from the trained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_data(X):\n",
    "    \n",
    "    classifier = load_model(r'../../data/SeaIceCNN.h5')\n",
    "\n",
    "    df = pd.read_pickle(r\"../../data/means_stds_S0_cnn.pkl\")\n",
    "    \n",
    "    for i in range(X.shape[3]):\n",
    "        \n",
    "        X[:,:,:,i] = ((X[:,:,:,i] - df.means.iloc[i]) / df.stds.iloc[i]).astype(np.float64)\n",
    "        \n",
    "    return np.concatenate(classifier.predict(X, use_multiprocessing=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training ice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "icedata_temp = np.load(r\"../../data/TrainingDataS0_ice_rev.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with the mean values of HH, HV, incidence angle and NESZ as well as the standard deviation of HH and HV for each 20x20 pixel subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'HH':np.mean(icedata_temp[:,:,:,0], axis=(1,2)),\n",
    "                  'HV':np.mean(icedata_temp[:,:,:,1], axis=(1,2)),\n",
    "                  'Angle':np.mean(icedata_temp[:,:,:,2], axis=(1,2)),\n",
    "                  'NESZ':np.mean(icedata_temp[:,:,:,3], axis=(1,2)),\n",
    "                  'std_HH':np.std(icedata_temp[:,:,:,0], axis=(1,2)),\n",
    "                  'std_HV':np.std(icedata_temp[:,:,:,1], axis=(1,2)),\n",
    "                  'cnn_prediction':class_data(icedata_temp)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test ice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icedata_temp = np.load(r\"../../data/TestDataS0_ice_rev.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the test data to the training data in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(pd.DataFrame({'HH':np.mean(icedata_temp[:,:,:,0], axis=(1,2)),\n",
    "                             'HV':np.mean(icedata_temp[:,:,:,1], axis=(1,2)),\n",
    "                             'Angle':np.mean(icedata_temp[:,:,:,2], axis=(1,2)),\n",
    "                             'NESZ':np.mean(icedata_temp[:,:,:,3], axis=(1,2)),\n",
    "                             'std_HH':np.std(icedata_temp[:,:,:,0], axis=(1,2)),\n",
    "                             'std_HV':np.std(icedata_temp[:,:,:,1], axis=(1,2)),\n",
    "                             'cnn_prediction':class_data(icedata_temp)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe to a pickle file <br>\n",
    "Note: This file is included in the shared data on Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(r'../../data/AllIceDF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the numpy 4D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del icedata_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the water training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterdata_temp = np.load(r\"../../data/TrainingDataS0_water_rev.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the dataframe for the water subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'HH':np.mean(waterdata_temp[:,:,:,0], axis=(1,2)),\n",
    "                  'HV':np.mean(waterdata_temp[:,:,:,1], axis=(1,2)),\n",
    "                  'Angle':np.mean(waterdata_temp[:,:,:,2], axis=(1,2)),\n",
    "                  'NESZ':np.mean(waterdata_temp[:,:,:,3], axis=(1,2)),\n",
    "                  'std_HH':np.std(waterdata_temp[:,:,:,0], axis=(1,2)),\n",
    "                  'std_HV':np.std(waterdata_temp[:,:,:,1], axis=(1,2)),\n",
    "                  'cnn_prediction':class_data(waterdata_temp)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test water data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterdata_temp = np.load(r\"../../data/TestDataS0_water_rev.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the test data to the training data in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(pd.DataFrame({'HH':np.mean(waterdata_temp[:,:,:,0], axis=(1,2)),\n",
    "                             'HV':np.mean(waterdata_temp[:,:,:,1], axis=(1,2)),\n",
    "                             'Angle':np.mean(waterdata_temp[:,:,:,2], axis=(1,2)),\n",
    "                             'NESZ':np.mean(waterdata_temp[:,:,:,3], axis=(1,2)),\n",
    "                             'std_HH':np.std(waterdata_temp[:,:,:,0], axis=(1,2)),\n",
    "                             'std_HV':np.std(waterdata_temp[:,:,:,1], axis=(1,2)),\n",
    "                             'cnn_prediction':class_data(waterdata_temp)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe to a pickle file\n",
    "Note: This file is included in the shared data on Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(r'../../data/AllWaterDF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the water 4D numpy array and the temporary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del waterdata_temp, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfice = pd.read_pickle(r'../../data/AllIceDF.pkl')\n",
    "dfwater = pd.read_pickle(r'../../data/AllWaterDF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate dataframes that are sorted into incidence angle \"bins\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(19, 51)\n",
    "\n",
    "wat_ang = dfwater.groupby(pd.cut(dfwater['Angle'],bins=bins))\n",
    "ice_ang = dfice.groupby(pd.cut(dfice['Angle'],bins=bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a curve for the NESZ of a SCWA image <br>\n",
    "Note: This section cannot be reproduced unless you have access to a RSAT-2 image product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ET.parse(r\"product.xml\")\n",
    "root = m.getroot()\n",
    "\n",
    "for lut in root.iter('{http://www.rsi.ca/rs2/prod/xml/schemas}referenceNoiseLevel'):\n",
    "\n",
    "    if lut.attrib['incidenceAngleCorrection'] == 'Sigma Nought':\n",
    "\n",
    "        steps = int(lut.findall('{http://www.rsi.ca/rs2/prod/xml/schemas}stepSize')[0].text)\n",
    "        first_value = int(lut.findall('{http://www.rsi.ca/rs2/prod/xml/schemas}pixelFirstNoiseValue')[0].text)\n",
    "        noise = np.array(lut.findall('{http://www.rsi.ca/rs2/prod/xml/schemas}noiseLevelValues')[0].text.split(' '),np.float32)\n",
    "\n",
    "gains_temp = np.zeros(10523, np.float32)\n",
    "gains_temp[first_value::steps] = np.power(10, noise/10)\n",
    "kernel = signal.triang(2*steps - 1)\n",
    "gains_interp = 10 * np.log10(scipy.ndimage.filters.convolve(gains_temp, kernel, mode=\"constant\"))\n",
    "\n",
    "pref = root.tag.strip('product')\n",
    "nearang = np.float32(root.find(pref + 'imageGenerationParameters').find(pref + 'sarProcessingInformation').find(pref + 'incidenceAngleNearRange').text)\n",
    "farang = np.float32(root.find(pref + 'imageGenerationParameters').find(pref + 'sarProcessingInformation').find(pref + 'incidenceAngleFarRange').text)\n",
    "incang = np.interp(np.arange(10523),[0,len(np.arange(10523))-1],[farang,nearang])\n",
    "\n",
    "incang_norm = [(x - np.min(incang)) / (np.max(incang) - np.min(incang)) * (len(bins) - 2) + 1 for x in incang]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a polynomial curve to fit the datasets (see figures below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "def func2(x, a, b, c):\n",
    "    return a*x**2+b*x+c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure: Box plots of the mean HH distributions for all the subsamples\n",
    "\n",
    "## Results: The polynomial fits with their correlation coefficients are provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,10))\n",
    "bp1 = ax1.boxplot(ice_ang['HH'].unique(), whis = [5, 95], sym = '', \n",
    "            labels = bins[0:-1], positions = np.arange(0.8, len(bins)-0.2, 1), \n",
    "            widths = 0.3, patch_artist = True)\n",
    "bp2 = ax1.boxplot(wat_ang['HH'].unique(), whis = [5, 95], sym = '',\n",
    "            labels = bins[0:-1], positions = np.arange(1.2, len(bins), 1),\n",
    "            widths = 0.3, patch_artist = True)\n",
    "\n",
    "ice_hh_med = []\n",
    "for med in bp1['medians']:\n",
    "    ice_hh_med.append(med.get_ydata()[0])    \n",
    "water_hh_med = []\n",
    "for med in bp2['medians']:\n",
    "    water_hh_med.append(med.get_ydata()[0])\n",
    "popt, pcov = curve_fit(func2, bins[:-1], np.array(water_hh_med))\n",
    "popt2, pcov2 = curve_fit(func2, bins[:-1], np.array(ice_hh_med))\n",
    "\n",
    "r2_ice=1-np.sum((ice_hh_med-func2(bins[:-1],*popt2))**2)/np.sum((ice_hh_med-np.mean(ice_hh_med))**2)\n",
    "r2_water=1-np.sum((water_hh_med-func2(bins[:-1],*popt))**2)/np.sum((water_hh_med-np.mean(water_hh_med))**2)\n",
    "\n",
    "line1 = ax1.plot(np.arange(1.2, len(bins), 1), func2(bins[:-1],*popt), '-b', linewidth=2)\n",
    "line2 = ax1.plot(np.arange(0.8, len(bins)-.2, 1), func2(bins[:-1],*popt2), '-g', linewidth=2)\n",
    "line3 = ax1.plot(incang_norm, gains_interp, '-r', linewidth = 3)\n",
    "\n",
    "for box in bp1['boxes']:\n",
    "    box.set(facecolor = 'green')\n",
    "    \n",
    "\n",
    "for box in bp2['boxes']:\n",
    "    box.set(facecolor = 'blue')\n",
    "ax1.set_xlim(0,31)\n",
    "ax1.set_xticks(np.arange(0, len(bins)+2,2))\n",
    "ax1.set_xticklabels(np.arange(18, 51,2).tolist(), fontweight = 'bold', fontsize = 22)\n",
    "ax1.set_ylim(-30,0)\n",
    "ax1.set_yticklabels(['-30','-25','-20','-15','-10','-5','0'], fontweight = 'bold', fontsize = 22)\n",
    "ax1.set_ylabel(r'$\\sigma^0$ [HH] (dB)', fontsize = 26, fontweight = 'bold')\n",
    "ax1.set_xlabel(r'Incidence Angle ($^O$)', fontsize = 26, fontweight = 'bold')\n",
    "ax1.legend([bp1[\"boxes\"][0], bp2[\"boxes\"][0], line3[0]], ['Ice', 'Water', 'NESZ'], loc='upper right', fontsize=26)\n",
    "\n",
    "print('\\u03C3\\u00b0[ice] = %5.3f\\u03B8\\u00b2 %5.3f\\u03B8 %5.3f , R\\u00b2=%5.3f' % tuple(np.append(popt2,r2_ice)))\n",
    "print('\\u03C3\\u00b0[water] = %5.3f\\u03B8\\u00b2 %5.3f\\u03B8 + %5.3f , R\\u00b2=%5.3f' % tuple(np.append(popt,r2_water)))\n",
    "\n",
    "fig.savefig(r'../../figures/Figure3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "σ°[ice] = 0.006θ² -0.632θ -4.885 , R²=0.995 <br>\n",
    "σ°[water] = 0.023θ² -2.263θ + 29.997 , R²=0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../../data/figures/Figure3.png\" height=\"500px\"></center>\n",
    "\n",
    "<center>Figure 3. Backscatter intensity (σ0) distribution per degree of incidence angle for the HH channel. Orange line is the median, boxes correspond to the 1st and 3rd quartile and whiskers represent the 5th and 95th percentile. Red line corresponds to the ScanSAR noise floor (NESZ).</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure: Same boxplots for the mean HV values of all the subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize=(15,10))\n",
    "bp3 = ax2.boxplot(ice_ang.HV.unique(), whis = [5, 95], sym = '', \n",
    "            labels = bins[0:-1], positions = np.arange(0.8, len(bins)-0.2, 1), \n",
    "            widths = 0.3, patch_artist = True)\n",
    "bp4 = ax2.boxplot(wat_ang.HV.unique(), whis = [5, 95], sym = '',\n",
    "            labels = bins[0:-1], positions = np.arange(1.2, len(bins), 1),\n",
    "            widths = 0.3, patch_artist = True)\n",
    "l1 = ax2.plot(incang_norm, gains_interp, '-r', linewidth = 3)\n",
    "\n",
    "for box in bp3['boxes']:\n",
    "    box.set(facecolor = 'green')\n",
    "    \n",
    "\n",
    "for box in bp4['boxes']:\n",
    "    box.set(facecolor = 'blue')\n",
    "ax2.set_xlim(0,31)\n",
    "ax2.set_xticks(np.arange(0, len(bins)+2,2))\n",
    "ax2.set_xticklabels(np.arange(18, 51,2).tolist(), fontweight = 'bold', fontsize = 22)\n",
    "ax2.set_ylim(-32,-22)\n",
    "ax2.set_yticklabels(np.arange(-32, -21, 2).tolist(), fontweight = 'bold', fontsize = 22)\n",
    "ax2.set_ylabel(r'$\\sigma^0$ [HV] (dB)', fontsize = 26, fontweight = 'bold')\n",
    "ax2.set_xlabel(r'Incidence Angle ($^0$)', fontsize = 26, fontweight = 'bold')\n",
    "ax2.legend([bp3[\"boxes\"][0], bp4[\"boxes\"][0], l1[0]], ['Ice', 'Water', 'NESZ'], loc='upper right', fontsize=26)\n",
    "fig.savefig(r'../../figures/Figure4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../../data/figures/Figure4.png\" height=\"500px\"></center>\n",
    "\n",
    "<center>Figure 4. Backscatter intensity (σ0) distribution per degree of incidence angle for the HV channel. Orange line is the median, boxes correspond to the 1st and 3rd quartile and whiskers represent the 5th and 95th percentile. Red line corresponds to the ScanSAR noise floor (NESZ).</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
